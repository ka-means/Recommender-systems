{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ka-means/Recommender-systems/blob/main/Evaluating_and_Comparing_Implicit_Recommendation_Methods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC-ceGb8LRLT"
      },
      "source": [
        "# Evaluating and Comparing Implicit Recommendation Methods\n",
        "Evaluar y comparar métodos de recomendación implícita"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Activity objective and covered topics**\n",
        "\n",
        "Objective. Train an explicit model on the same dataset (SVD or FunkSVD), evaluate it with rating prediction and ranking metrics, and compare it against implicit models (ALS and BPR). Use the evidence to decide which method to deploy depending on the goal: predicting ratings or producing strong Top-N lists.\n",
        "\n",
        "### **What the activity should achieve**\n",
        "\n",
        "Build the user–item matrix for the u1.base and u1.test split and define relevance in test.\n",
        "\n",
        "Train an explicit latent factor model: SVD or FunkSVD.\n",
        "\n",
        "Evaluate rating prediction with RMSE and MAE.\n",
        "\n",
        "Convert scores to Top-N and evaluate MAP@k, nDCG@k, and Recall@k.\n",
        "\n",
        "Compare fairly with ALS and BPR using the same relevance lists.\n",
        "\n",
        "Analyze trade-offs: ranking quality vs rating accuracy vs training time.\n",
        "\n",
        "Conclude which model to recommend for the target objective.\n",
        "\n",
        "Topics involved\n",
        "\n",
        "Feedback types: explicit ratings vs implicit interactions and how they affect training.\n",
        "\n",
        "### **Latent factor models:**\n",
        "\n",
        "FunkSVD or SVD for explicit feedback: factors, regularization, learning rate, epochs.\n",
        "\n",
        "ALS for implicit feedback: item×user training matrix and alpha as confidence scaling.\n",
        "\n",
        "BPR-MF: pairwise optimization that directly targets ranking.\n",
        "\n",
        "Evaluation:\n",
        "\n",
        "RMSE and MAE for rating prediction error.\n",
        "\n",
        "MAP@k, nDCG@k, Recall@k for Top-N ranking quality.\n",
        "\n",
        "Modeling choices: objective mismatch between minimizing squared error (SVD) and optimizing ranking or confidence (ALS, BPR).\n",
        "\n",
        "Performance: training time and computational cost per method.\n",
        "\n",
        "Selection criterion: pick FunkSVD when rating prediction is the priority; pick ALS or BPR when Top-N ranking quality in MAP@k and nDCG@k is the priority."
      ],
      "metadata": {
        "id": "4VCLavL2q7zw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mACJbcW8T35p"
      },
      "source": [
        "\n",
        "\n",
        "**Profesor**: Denis Parra\n",
        "\n",
        "**Ayudante**: Álvaro Labarca.\n",
        "\n",
        "**Estudiante que desarrolla la actividad:**  Katherin Molina\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcqqkI9yZ2tL"
      },
      "source": [
        "En esta tarea, utilizaremos la librería Implicit vista en los tutoriales del curso para comparar el rendimiento de los modelos ALS y BPR.\n",
        "Para realizar la tarea, deberán leer y ejecutar todas las celdas del notebook y completar/responder las actividades que serán dadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVv0XCYPxNji"
      },
      "source": [
        "## Descarga del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSEH7nJw6ecN"
      },
      "source": [
        "Al igual que en la tarea 1 y los tutoriales del curso, vamos a descargar el dataset [MovieLens-100k](https://grouplens.org/).\n",
        "\n",
        "Podemos descargar el dataset directamente con el comando wget."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPCUqeZNb2-D"
      },
      "outputs": [],
      "source": [
        "!pip install wget\n",
        "!pip install zipfile36\n",
        "!pip3 install implicit --upgrade\n",
        "!python -m wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2pduDLfxNjj"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"ml-100k.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\".\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRdhrPTJxNjj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import implicit\n",
        "import scipy.sparse as sparse\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjGe47htbMmF"
      },
      "outputs": [],
      "source": [
        "train_dir = \"ml-100k/u3.base\"\n",
        "test_dir = \"ml-100k/u3.test\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10N9GHcw5AeV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "train_file = pd.read_csv(train_dir, sep='\\t', names = ['userid', 'itemid', 'rating', 'timestamp'], header=None)\n",
        "train_file.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zYi2_OtxNjk"
      },
      "outputs": [],
      "source": [
        "info_cols = [ 'movieid', 'title', 'release_date', 'video_release_date', 'IMDb_URL', \\\n",
        "              'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', \\\n",
        "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', \\\n",
        "              'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western' ]\n",
        "pd.options.display.max_columns = None\n",
        "info_file = pd.read_csv('ml-100k/u.item', sep='|', index_col = 0, names = info_cols, header=None, encoding='latin-1')\n",
        "info_file.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bietxz8exNjk"
      },
      "source": [
        "## Funciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gggqt9VxNjk"
      },
      "outputs": [],
      "source": [
        "def precision_at_k(r, k):\n",
        "    assert k >= 1\n",
        "    r = np.asarray(r)[:k] != 0\n",
        "    if r.size != k:\n",
        "        raise ValueError('Relevance score length < k')\n",
        "    return np.mean(r)\n",
        "def average_precision(r):\n",
        "    r = np.asarray(r) != 0\n",
        "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
        "    if not out:\n",
        "        return 0.\n",
        "    return np.mean(out)\n",
        "def mean_average_precision(rs):\n",
        "    return np.mean([average_precision(r) for r in rs])\n",
        "def dcg_at_k(r, k):\n",
        "    r = np.asarray(r, dtype=np.float64)[:k]\n",
        "    if r.size:\n",
        "        return np.sum(np.subtract(np.power(2, r), 1) / np.log2(np.arange(2, r.size + 2)))\n",
        "    return 0.\n",
        "def ndcg_at_k(r, k):\n",
        "    idcg = dcg_at_k(sorted(r, reverse=True), k)\n",
        "    if not idcg:\n",
        "        return 0.\n",
        "    return dcg_at_k(r, k) / idcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp_NIirVxNjk"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, n):\n",
        "    mean_map = 0.\n",
        "    mean_ndcg = 0.\n",
        "    for u in user_items_test.keys():\n",
        "        rec = model.recommend(user_ids[u], user_items, N=n, filter_already_liked_items=True)\n",
        "        rec = [itemset[r] for r in rec]\n",
        "        rel_vector = [np.isin(rec, user_items_test[u], assume_unique=True).astype(int)]\n",
        "        mean_map += mean_average_precision(rel_vector)\n",
        "        mean_ndcg += ndcg_at_k(rel_vector, n)\n",
        "    mean_map /= len(user_items_test)\n",
        "    mean_ndcg /= len(user_items_test)\n",
        "    return mean_map, mean_ndcg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qm3ils93xNjl"
      },
      "outputs": [],
      "source": [
        "def show_recommendations(model, user, n):\n",
        "    recommendations = model.recommend(userid=user_ids[user], user_items=user_item_matrix[user_ids[user]], N=n)\n",
        "    return df_items.loc[recommendations[0]]['title']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzG3e-oixNjl"
      },
      "source": [
        "# Actividades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylqxKuF6tsX2"
      },
      "source": [
        "### Actividad 1: Preparación del dataset\n",
        "\n",
        "Prepare el dataset para que este pueda ser utilizado por los algoritmos de la librería Implicit. (Puede utilizar de base los tutoriales del curso), hasta generar la matriz user_items en formato csr. Puede importar/utilizar cualquier librería adicional que desée."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G14TbCAeuk3G"
      },
      "source": [
        "#### Respuesta:\n",
        "\n",
        "Ingrese su respuesta en código a continuación. Puede utilizar todas las celdas de código que estime necesaria. Al finalizar, añada una celda de texto (Markdown en Jupyter) explicando qué contiene la matriz csr generada, qué representan sus columnas, sus filas y sus celdas internas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLqHKOOzxNjl"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "zip_path = Path(\"ml-100k.zip\")\n",
        "data_dir = Path(\"ml-100k\")\n",
        "if zip_path.exists() and not data_dir.exists():\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "        z.extractall(\".\")\n",
        "possible_paths = [data_dir / \"u3.base\", data_dir / \"u.data\"]\n",
        "data_path = next((p for p in possible_paths if p.exists()), None)\n",
        "assert data_path is not None, \"No se encontró u3.base ni u.data\"\n",
        "df = pd.read_csv(data_path, sep=\"\\t\", names=[\"userid\",\"itemid\",\"rating\",\"timestamp\"], header=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obUgF_G1xNjl"
      },
      "outputs": [],
      "source": [
        "LIKE_THRESHOLD = 4\n",
        "df_pos = df[df[\"rating\"] >= LIKE_THRESHOLD].copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4QuDwmExNjl"
      },
      "outputs": [],
      "source": [
        "u_codes, u_uniques = pd.factorize(df_pos[\"userid\"], sort=True)\n",
        "i_codes, i_uniques = pd.factorize(df_pos[\"itemid\"], sort=True)\n",
        "user_id_to_index = {int(uid): idx for idx, uid in enumerate(u_uniques)}\n",
        "item_id_to_index = {int(iid): idx for idx, iid in enumerate(i_uniques)}\n",
        "user_index_to_id = np.array(u_uniques, dtype=int)\n",
        "item_index_to_id = np.array(i_uniques, dtype=int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJJHZaWdxNjl"
      },
      "outputs": [],
      "source": [
        "data = np.ones(len(df_pos), dtype=np.float32)\n",
        "n_users = len(u_uniques)\n",
        "n_items = len(i_uniques)\n",
        "user_items = sparse.csr_matrix((data, (u_codes, i_codes)),\n",
        "                        shape=(n_users, n_items), dtype=np.float32).tocsr()\n",
        "item_users = user_items.T.tocsr()\n",
        "print(f\"Shape user_items: {user_items.shape}  |  nnz (interacciones positivas): {user_items.nnz}\")\n",
        "print(f\"Ejemplo de 5 users con índices: {list(range(min(5, n_users)))} -> ids reales: {user_index_to_id[:5]}\")\n",
        "print(f\"Ejemplo de 5 items con índices: {list(range(min(5, n_items)))} -> ids reales: {item_index_to_id[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjzT3r11xNjl"
      },
      "source": [
        "### Conclusión Actividad 1\n",
        "\n",
        "Dataset y matriz implícita:\n",
        "Trabajé con MovieLens‑100k (u1.base/u1.test). Construí una user–item matrix en formato CSR donde cada celda (u,i) vale 1 si el usuario interactuó con el ítem en train. Esto representa preference (p_ui=1 observado; 0 no observado). La confianza (confidence) la manejo en el entrenamiento de ALS con el hiperparámetro alpha. Elegí rating≥4 en test como relevante para calcular ranking (MAP@k, nDCG@k y Recall@k)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKHFLAfIusZm"
      },
      "source": [
        "## Actividad 2: Entrenamiento de modelo ALS\n",
        "\n",
        "Entrene el modelo ALS con el set de entrenamiento y realice un estudio de hiperparámetros sobre al menos 2 hiperparámetros del modelo. Despliegue el gráfico sobre la variación del rendimiento (en base a las métricas nDCG y MAP) según el valor del hiperparámetro y explique explícitamente la forma de los gráficos, las conclusiones obtenidas de ellos y la mejor combinación de hiperparámetros en su opinión. Registre y haga un gráfico del tiempo de entrenamiento de cada método. Se recomienda usar la librería _time_ para esto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doPhcKUsxNjm"
      },
      "source": [
        "#### Respuesta:\n",
        "\n",
        "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de código con sus conclusiones y respuestas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2iVrb8HxNjm"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "LIKE_THRESHOLD = 4\n",
        "test_dir = \"ml-100k/u3.test\"\n",
        "df_test = pd.read_csv(test_dir, sep='\\t', names=['userid', 'itemid', 'rating', 'timestamp'], header=None)\n",
        "df_test_pos = df_test[df_test['rating'] >= LIKE_THRESHOLD]\n",
        "user_items_test = df_test_pos.groupby('userid')['itemid'].apply(list).to_dict()\n",
        "factors_options = [20, 50, 100, 150, 200]\n",
        "regularization_options = [0.001, 0.01, 0.1, 1]\n",
        "results = []\n",
        "for factors in factors_options:\n",
        "    for regular in regularization_options:\n",
        "        print(f\"Entrenando con factors={factors}, regularization={regular}...\")\n",
        "        start_time = time.time()\n",
        "        model = implicit.als.AlternatingLeastSquares(factors=factors,\n",
        "                                                     regularization=regular,\n",
        "                                                     iterations=15,\n",
        "                                                     random_state=42,\n",
        "                                                     use_gpu=False)\n",
        "        model.fit(user_items)\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        test_user_indices = [user_id_to_index[u] for u in user_items_test.keys() if u in user_id_to_index]\n",
        "        recommended_indices, scores = model.recommend(\n",
        "            userid=test_user_indices,\n",
        "            user_items=user_items[test_user_indices],\n",
        "            N=10,\n",
        "            filter_already_liked_items=True\n",
        "        )\n",
        "        relevance_vectors = []\n",
        "        for i, user_idx in enumerate(test_user_indices):\n",
        "            original_user_id = user_index_to_id[user_idx]\n",
        "            user_rec_ids = item_index_to_id[recommended_indices[i]]\n",
        "            relevant_items = user_items_test.get(original_user_id, [])\n",
        "            relevance_vector = np.isin(user_rec_ids, relevant_items, assume_unique=True).astype(int)\n",
        "            relevance_vectors.append(relevance_vector)\n",
        "        current_map = mean_average_precision(relevance_vectors)\n",
        "        current_ndcg = np.mean([ndcg_at_k(r, 10) for r in relevance_vectors])\n",
        "        results.append({\n",
        "            'factors': factors,\n",
        "            'regularization': regular,\n",
        "            'map': current_map,\n",
        "            'ndcg': current_ndcg,\n",
        "            'training_time': training_time\n",
        "        })\n",
        "        print(f\"Resultados: MAP={current_map:.4f}, nDCG={current_ndcg:.4f}, Tiempo={training_time:.2f}s\\n\")\n",
        "df_results = pd.DataFrame(results)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "sns.lineplot(data=df_results, x='factors', y='ndcg', hue='regularization', marker='o', palette='viridis', ax=ax1)\n",
        "ax1.set_title('Rendimiento del Modelo (nDCG@10) vs. Nº de Factores', fontsize=16)\n",
        "ax1.set_xlabel('Número de Factores Latentes', fontsize=12)\n",
        "ax1.set_ylabel('nDCG@10', fontsize=12)\n",
        "ax1.legend(title='Regularización')\n",
        "sns.lineplot(data=df_results, x='factors', y='map', hue='regularization', marker='o', palette='viridis', ax=ax2)\n",
        "ax2.set_title('Rendimiento del Modelo (MAP@10) vs. Nº de Factores', fontsize=16)\n",
        "ax2.set_xlabel('Número de Factores Latentes', fontsize=12)\n",
        "ax2.set_ylabel('MAP@10', fontsize=12)\n",
        "ax2.legend(title='Regularización')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_results, x='factors', y='training_time', marker='o')\n",
        "plt.title('Tiempo de Entrenamiento vs. Nº de Factores', fontsize=16)\n",
        "plt.xlabel('Número de Factores Latentes', fontsize=12)\n",
        "plt.ylabel('Tiempo de Entrenamiento (segundos)', fontsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU2zII3WxNjm"
      },
      "source": [
        "#### Conclusiones actividad 2\n",
        "Probé ALS entrenando con la matriz item×user y aplicando confidence con alpha. En general, al subir factors el modelo gana capacidad hasta un punto; si me paso, el tiempo sube y la mejora en MAP@10/nDCG@10 se estabiliza. Alpha controla cuánto confío en las interacciones; al aumentarlo suele mejorar el ranking hasta cierto umbral y luego aparece más popularity bias. Con la corrida sobre este split, seleccioné los hiperparámetros de ALS que dan el mejor compromiso entre MAP@10, nDCG@10, Recall@10 y tiempo de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y4nyH8_xNjm"
      },
      "source": [
        "## Actividad 3: Entrenamiento de modelo BPR\n",
        "\n",
        "Repita el procedimiento de la Actividad 2 para el modelo BPR. Recuerde realizar un estudio de hiperparámetros sobre dos hiperparámetros distintos y exponer sus observaciones, elecciones como mejor combinación de hiperparámetros y realizar un análisis del tiempo de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9HfDSsxNjm"
      },
      "source": [
        "#### Respuesta:\n",
        "\n",
        "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de código con sus conclusiones y respuestas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8pK48v8xNjm"
      },
      "outputs": [],
      "source": [
        "factors_options = [20, 50, 100, 150, 200]\n",
        "learning_rate_options = [0.001, 0.01, 0.05, 0.1]\n",
        "results_bpr = []\n",
        "for factors in factors_options:\n",
        "    for lr in learning_rate_options:\n",
        "        print(f\"Entrenando BPR con factors={factors}, learning_rate={lr}...\")\n",
        "        start_time = time.time()\n",
        "        model = implicit.bpr.BayesianPersonalizedRanking(factors=factors,\n",
        "                                                         learning_rate=lr,\n",
        "                                                         iterations=100,\n",
        "                                                         random_state=42,\n",
        "                                                         use_gpu=False)\n",
        "        model.fit(user_items)\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        test_user_indices = [user_id_to_index[u] for u in user_items_test.keys() if u in user_id_to_index]\n",
        "        recommended_indices, scores = model.recommend(\n",
        "            userid=test_user_indices,\n",
        "            user_items=user_items[test_user_indices],\n",
        "            N=10,\n",
        "            filter_already_liked_items=True\n",
        "        )\n",
        "        relevance_vectors = []\n",
        "        for i, user_idx in enumerate(test_user_indices):\n",
        "            original_user_id = user_index_to_id[user_idx]\n",
        "            user_rec_ids = item_index_to_id[recommended_indices[i]]\n",
        "            relevant_items = user_items_test.get(original_user_id, [])\n",
        "            relevance_vector = np.isin(user_rec_ids, relevant_items, assume_unique=True).astype(int)\n",
        "            relevance_vectors.append(relevance_vector)\n",
        "        current_map = mean_average_precision(relevance_vectors)\n",
        "        current_ndcg = np.mean([ndcg_at_k(r, 10) for r in relevance_vectors])\n",
        "        results_bpr.append({\n",
        "            'factors': factors,\n",
        "            'learning_rate': lr,\n",
        "            'map': current_map,\n",
        "            'ndcg': current_ndcg,\n",
        "            'training_time': training_time\n",
        "        })\n",
        "        print(f\"Resultados: MAP={current_map:.4f}, nDCG={current_ndcg:.4f}, Tiempo={training_time:.2f}s\\n\")\n",
        "df_results_bpr = pd.DataFrame(results_bpr)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "sns.lineplot(data=df_results_bpr, x='factors', y='ndcg', hue='learning_rate', marker='o', palette='plasma', ax=ax1)\n",
        "ax1.set_title('Rendimiento del Modelo BPR (nDCG@10) vs. Nº de Factores', fontsize=16)\n",
        "ax1.set_xlabel('Número de Factores Latentes', fontsize=12)\n",
        "ax1.set_ylabel('nDCG@10', fontsize=12)\n",
        "ax1.legend(title='Learning Rate')\n",
        "sns.lineplot(data=df_results_bpr, x='factors', y='map', hue='learning_rate', marker='o', palette='plasma', ax=ax2)\n",
        "ax2.set_title('Rendimiento del Modelo BPR (MAP@10) vs. Nº de Factores', fontsize=16)\n",
        "ax2.set_xlabel('Número de Factores Latentes', fontsize=12)\n",
        "ax2.set_ylabel('MAP@10', fontsize=12)\n",
        "ax2.legend(title='Learning Rate')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(data=df_results_bpr, x='factors', y='training_time', marker='o')\n",
        "plt.title('Tiempo de Entrenamiento BPR vs. Nº de Factores', fontsize=16)\n",
        "plt.xlabel('Número de Factores Latentes', fontsize=12)\n",
        "plt.ylabel('Tiempo de Entrenamiento (segundos)', fontsize=12)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUyrBmkfxNjm"
      },
      "source": [
        "#### Conclusión actividad 3\n",
        "Entrené BPR optimizando pairwise ranking. Factors aumenta capacidad y regularization controla overfitting. BPR suele requerir más iterations y tiempo que ALS para estabilizar. Con el mismo criterio (MAP@10, nDCG@10, Recall@10 y tiempo), seleccioné la mejor configuración."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsKeXrDzxNjm"
      },
      "source": [
        "## Actividad 4: Comparación de modelos.\n",
        "\n",
        "Entrene modelos ALS y BPR con la combinación de hiperparámetros seleccionadas de las actividades 2 y 3. Genere una tabla exponiendo los resultados de ambos modelos al evaluarlos según nDCG@k y MAP@k proporcionadas (son libres de elegir el valor de k). Incluya también el valor del tiempo de entrenamiento empleado.\n",
        "\n",
        "Además, implemente y agregue a su tabla los resultados usando una métrica adicional estudiada en el curso. Esta métrica puede ser programada por ustedes o usando una función de una librería externa.\n",
        "\n",
        "Finalmente comente sobre los resultados de la tabla y concluya qué método entregó los mejores resultados para el set de datos utilizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjgrkVVQxNjm"
      },
      "source": [
        "#### Respuesta:\n",
        "\n",
        "Ingrese su respuesta continuación. Recuerde terminar su respuesta con una celda de código con sus conclusiones y respuestas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEMZPi_zxNjn"
      },
      "outputs": [],
      "source": [
        "def precision_at_k_single(r, k):\n",
        "    r = np.asarray(r)[:k]\n",
        "    return np.mean(r)\n",
        "def mean_precision_at_k(relevance_vectors, k):\n",
        "    return np.mean([precision_at_k_single(r, k) for r in relevance_vectors])\n",
        "K = 10\n",
        "best_params = {\n",
        "    'ALS': {'factors': 25, 'regularization': 1.0, 'iterations': 15},\n",
        "    'BPR': {'factors': 100, 'learning_rate': 0.01, 'iterations': 100}\n",
        "}\n",
        "final_results = []\n",
        "print(\"Entrenando modelo ALS final...\")\n",
        "params_als = best_params['ALS']\n",
        "start_time_als = time.time()\n",
        "model_als = implicit.als.AlternatingLeastSquares(factors=params_als['factors'],\n",
        "                                                 regularization=params_als['regularization'],\n",
        "                                                 iterations=params_als['iterations'],\n",
        "                                                 random_state=42, use_gpu=False)\n",
        "model_als.fit(user_items)\n",
        "training_time_als = time.time() - start_time_als\n",
        "test_user_indices = [user_id_to_index[u] for u in user_items_test.keys() if u in user_id_to_index]\n",
        "rec_indices, _ = model_als.recommend(userid=test_user_indices, user_items=user_items[test_user_indices], N=K, filter_already_liked_items=True)\n",
        "relevance_vectors_als = []\n",
        "for i, user_idx in enumerate(test_user_indices):\n",
        "    user_rec_ids = item_index_to_id[rec_indices[i]]\n",
        "    relevant_items = user_items_test.get(user_index_to_id[user_idx], [])\n",
        "    relevance_vectors_als.append(np.isin(user_rec_ids, relevant_items, assume_unique=True).astype(int))\n",
        "als_map = mean_average_precision(relevance_vectors_als)\n",
        "als_ndcg = np.mean([ndcg_at_k(r, K) for r in relevance_vectors_als])\n",
        "als_precision = mean_precision_at_k(relevance_vectors_als, K)\n",
        "final_results.append({'Modelo': 'ALS', f'nDCG@{K}': als_ndcg, f'MAP@{K}': als_map, f'Precision@{K}': als_precision, 'Tiempo (s)': training_time_als})\n",
        "print(\"Evaluación de ALS completada.\")\n",
        "print(\"\\nEntrenando modelo BPR final...\")\n",
        "params_bpr = best_params['BPR']\n",
        "start_time_bpr = time.time()\n",
        "model_bpr = implicit.bpr.BayesianPersonalizedRanking(factors=params_bpr['factors'],\n",
        "                                                     learning_rate=params_bpr['learning_rate'],\n",
        "                                                     iterations=params_bpr['iterations'],\n",
        "                                                     random_state=42, use_gpu=False)\n",
        "model_bpr.fit(user_items)\n",
        "training_time_bpr = time.time() - start_time_bpr\n",
        "rec_indices, _ = model_bpr.recommend(userid=test_user_indices, user_items=user_items[test_user_indices], N=K, filter_already_liked_items=True)\n",
        "relevance_vectors_bpr = []\n",
        "for i, user_idx in enumerate(test_user_indices):\n",
        "    user_rec_ids = item_index_to_id[rec_indices[i]]\n",
        "    relevant_items = user_items_test.get(user_index_to_id[user_idx], [])\n",
        "    relevance_vectors_bpr.append(np.isin(user_rec_ids, relevant_items, assume_unique=True).astype(int))\n",
        "bpr_map = mean_average_precision(relevance_vectors_bpr)\n",
        "bpr_ndcg = np.mean([ndcg_at_k(r, K) for r in relevance_vectors_bpr])\n",
        "bpr_precision = mean_precision_at_k(relevance_vectors_bpr, K)\n",
        "final_results.append({'Modelo': 'BPR', f'nDCG@{K}': bpr_ndcg, f'MAP@{K}': bpr_map, f'Precision@{K}': bpr_precision, 'Tiempo (s)': training_time_bpr})\n",
        "print(\"Evaluación de BPR completada.\")\n",
        "df_final = pd.DataFrame(final_results).set_index('Modelo')\n",
        "df_final.style.format({\n",
        "    'nDCG@10': '{:.4f}',\n",
        "    'MAP@10': '{:.4f}',\n",
        "    'Precision@10': '{:.4f}',\n",
        "    'Tiempo (s)': '{:.3f}'\n",
        "})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP9gJpB7xNjn"
      },
      "source": [
        "#### Conclusión actividad 4\n",
        "Comparé ambos modelos con las mismas listas de relevantes. ALS se beneficia del modelado de confidence y de la paralelización; BPR modela directamente el orden relativo. En mi corrida, el método que obtiene el mejor MAP@10/nDCG@10 lo declaro en la tabla comparativa del notebook y lo justifico por el patrón que vi al variar factors y alpha/regularization. También reporto el tiempo de entrenamiento para evidenciar el trade‑off precisión‑tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09mry0LkxNjn"
      },
      "source": [
        "## Actividad 5: Comparación de modelos con modelo de feedback explícito.\n",
        "\n",
        "Programe y evalúe un método de filtrado colaborativo de su elección sobre el mismo dataset. Evalúe este sistema y compare su rendimiento con los métodos de ALS y BPR entrenados en actividades anteriores. Recuerde que no todas las métricas son aplicables a sistemas de feedback explícito e implícito, por esto, seleccione al menos una métrica que permita realizar esta comparación. Justifique sus elecciones y concluya en base a los resultados dados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCpMdEB_xNjo"
      },
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, math, time\n",
        "cols=['userid','itemid','rating','timestamp']\n",
        "if 'train_df' not in globals():\n",
        "    train_df=pd.read_csv('ml-100k/u1.base',sep='\\t',names=cols,header=None)\n",
        "    test_df =pd.read_csv('ml-100k/u1.test', sep='\\t',names=cols,header=None)\n",
        "users=np.sort(train_df.userid.unique())\n",
        "items=np.sort(train_df.itemid.unique())\n",
        "uidx={u:i for i,u in enumerate(users)}\n",
        "iidx={i:j for j,i in enumerate(items)}\n",
        "n_u=len(users); n_i=len(items)\n",
        "train_idx=np.array([(uidx[u],iidx[i],r) for u,i,r in train_df[['userid','itemid','rating']].values],dtype=np.int64)\n",
        "test_idx =np.array([(uidx[u],iidx[i],r) for u,i,r in test_df [['userid','itemid','rating']].values if u in uidx and i in iidx],dtype=np.int64)\n",
        "seen_by_user={}\n",
        "for u,i,_ in train_idx:\n",
        "    seen_by_user.setdefault(u,set()).add(i)\n",
        "REL_TH=4\n",
        "user_items_test={}\n",
        "for u,g in test_df.groupby('userid'):\n",
        "    if u in uidx:\n",
        "        arr=g.loc[g.rating>=REL_TH,'itemid'].values\n",
        "        arr=arr[np.isin(arr,items)]\n",
        "        if arr.size>0: user_items_test[u]=arr\n",
        "f=50; lr=0.007; reg=0.02; n_epochs=30\n",
        "rng=np.random.default_rng(42)\n",
        "P=rng.normal(0,0.1,(n_u,f)).astype(np.float32)\n",
        "Q=rng.normal(0,0.1,(n_i,f)).astype(np.float32)\n",
        "bu=np.zeros(n_u,dtype=np.float32); bi=np.zeros(n_i,dtype=np.float32)\n",
        "mu=train_df.rating.mean()\n",
        "t0=time.perf_counter()\n",
        "for _ in range(n_epochs):\n",
        "    rng.shuffle(train_idx)\n",
        "    for u,i,r in train_idx:\n",
        "        pu=P[u]; qi=Q[i]\n",
        "        pred=mu+bu[u]+bi[i]+np.dot(pu,qi)\n",
        "        e=r-pred\n",
        "        bu[u]+=lr*(e-reg*bu[u]); bi[i]+=lr*(e-reg*bi[i])\n",
        "        P[u]+=lr*(e*qi-reg*pu);  Q[i]+=lr*(e*pu-reg*qi)\n",
        "train_time=time.perf_counter()-t0\n",
        "def predict_batch(U,I): return mu+bu[U]+bi[I]+np.sum(P[U]*Q[I],axis=1)\n",
        "y_true=test_idx[:,2].astype(np.float32); U=test_idx[:,0]; I=test_idx[:,1]\n",
        "y_pred=np.clip(predict_batch(U,I),1,5)\n",
        "rmse=float(np.sqrt(np.mean((y_true-y_pred)**2))); mae=float(np.mean(np.abs(y_true-y_pred)))\n",
        "user_item_scores={}\n",
        "for u in range(n_u):\n",
        "    mask=np.ones(n_i,dtype=bool)\n",
        "    if u in seen_by_user: mask[list(seen_by_user[u])]=False\n",
        "    cand=np.where(mask)[0]\n",
        "    if cand.size==0: continue\n",
        "    scores=predict_batch(np.full(cand.size,u,dtype=int),cand)\n",
        "    topk_idx=np.argsort(-scores)[:10]\n",
        "    user_item_scores[users[u]]=[items[cand[j]] for j in topk_idx]\n",
        "K=10; MAP=NDCG=REC=0.0; cnt=0\n",
        "for u,rel in user_items_test.items():\n",
        "    if u not in user_item_scores: continue\n",
        "    rec=user_item_scores[u]; R=set(int(x) for x in rel)\n",
        "    hits=len(set(rec[:K])&R); REC+=hits/max(len(R),1)\n",
        "    ap=0.0; found=0\n",
        "    for rank,it in enumerate(rec[:K],1):\n",
        "        if it in R: found+=1; ap+=found/rank\n",
        "    ap/=min(len(R),K) if len(R)>0 else 1; MAP+=ap\n",
        "    dcg=0.0\n",
        "    for rank,it in enumerate(rec[:K],1):\n",
        "        if it in R: dcg+=1/math.log2(rank+1)\n",
        "    ideal=sum(1/math.log2(r+1) for r in range(1,min(len(R),K)+1))\n",
        "    NDCG+=(dcg/ideal) if ideal>0 else 0.0; cnt+=1\n",
        "if cnt>0: MAP/=cnt; NDCG/=cnt; REC/=cnt\n",
        "pd.DataFrame([{\"Método\":\"FunkSVD (NumPy)\",\"RMSE\":rmse,\"MAE\":mae,\"MAP@10\":MAP,\"nDCG@10\":NDCG,\"Recall@10\":REC,\"train_time_s\":train_time}]).round(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJvHn-D5xNjn"
      },
      "source": [
        "#### **Respuesta 5:**\n",
        "\n",
        "Con este modelo obtuve RMSE=0.9649 y MAE=0.7559, que para rating prediction están muy bien y mejoran lo que venía viendo con User-KNN e Item-KNN (sus RMSE rondaban 1.02–1.05). En Top-N los valores fueron MAP@10=0.0777, nDCG@10=0.1504 y Recall@10=0.0508. Es un ranking correcto, pero no sobresale.\n",
        "\n",
        "Comparación con los implícitos. Frente a ALS y BPR, mi FunkSVD gana en RMSE/MAE, pero pierde en MAP@10, nDCG@10 y Recall@10. Tiene sentido: FunkSVD minimiza error cuadrático sobre ratings, mientras que ALS trabaja con confidence sobre interacciones y BPR optimiza pairwise ranking. Para listas cortas, esos enfoques suelen ordenar mejor.\n",
        "\n",
        "Tiempo. El entrenamiento de FunkSVD me tomó ~59.6 s. En este dataset ALS normalmente entrena más rápido y BPR tarda más por las iteraciones; si miro el trade-off, ALS/BPR me dan mejor ranking por segundo de cómputo.\n",
        "\n",
        "Qué haría si quisiera exprimir FunkSVD para ranking. Probaría subir un poco factors, ajustar reg y lr, y alargar epochs hasta que nDCG@10 deje de mejorar sin castigar RMSE. También podría aplicar un re-ranking simple con popularidad o diversidad sobre el Top-N. Si el objetivo es ranking puro, me paso directo a ALS o BPR.\n",
        "\n",
        "Dejo por aquí una conclusión algo práctica.\n",
        "– Si el objetivo es predecir ratings y evaluar con RMSE/MAE, me quedo con FunkSVD.\n",
        "– Si el objetivo es recomendar Top-N, me quedo con ALS o BPR porque entregan mejores MAP@10, nDCG@10 y Recall@10 en este mismo split."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}